{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliMorabih/Classify-images-of-cats-and-dogs-with-Artificial-Intelligence/blob/master/CNNCodeCatorDog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUVU2OQx-pLR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66d9deaf-91d1-47d0-e154-4dd2003773c1"
      },
      "source": [
        "import tensorflow as tf\n",
        "  \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6gcMHe13-u9h",
        "outputId": "1e8836bd-3ece-4378-fd1d-e919c0605de8"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Epup7mUF_Fc5"
      },
      "source": [
        "We will apply transformation only the images of the training set only, the reason why we need only to do the transformation on the traning set to avoid the overfiting  \n",
        "\n",
        "```\n",
        "# the transformations is some zoom or rotation for images\n",
        "we need to shift some of the pixels than we gonna rotate a litle bit the image\n",
        "horozantal flips pr zoom out or zoom in  We call the image augmentatiion because we dont wanna the model over learn \n",
        "rescale = 1./255 :  this willapply feature scalling for each and every single of one of your pixel by deviding their value by 255 because as we know each pixel take a number between  0 and 255 so by deviding all of them by 255 we endeed get all the pixel value between 0 and 1 \n",
        "Batch size is how many pictures on eatch batch\n",
        "Binary : we will choose if Cat ot Dog so i banary\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rdlu99RtL-On",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "162373b0-0170-4d65-e7f5-4144504e3200"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/dataset/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6608 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJqEcjEdPQRo"
      },
      "source": [
        "*# We need to keep the same size as the traning set 64 and 64 *"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2b1UmT7O1bJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd160351-5ade-46df-ec76-8a0e4f409490"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/dataset/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9IEL6b2PctM"
      },
      "source": [
        "# Now we gona start building CNN\n",
        "# initialiting CNN\n",
        "\n",
        " call tenserflor from keras library from models from sequantial class \n",
        "*texte en italique*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAWcX8FBPmPz"
      },
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYKa8AqCP7h2"
      },
      "source": [
        "# ADD the first convolution later \n",
        " \n",
        "filters=32 is the number of features detecter we want to apply to the images \n",
        "kernel_size=3 is the size of that feature detecter mean number of rows and number of column \n",
        "activation='relu' : Relu fonction is the rectify activation fonction \n",
        "input_shape=[64, 64, 3] : when u add your very first layer convolution later or dense later we have to spicify the input shape of your input  , sice we resize our image down to 64 by 64  the input will be 64 by 64 and 3 because is RGB\n",
        "\n",
        "> Bloc en retrait\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piU2eC9dQFMu"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePvZe92nS78A"
      },
      "source": [
        "Step Pooling \n",
        "\n",
        "we need to take cnn object and add methode max pooling layer \n",
        "recomandation size 2 for max pooling \n",
        "if we use the pading we use an extra colomn \n",
        "Pool_size 2 by 2 frame \n",
        "strides we wanna shift that frame every 2 pixeles "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7MQofXYTJWx"
      },
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEtEikuDUabd"
      },
      "source": [
        "# ADD the second convolutional later \n",
        "we dont need to remove the inputshape for second layer because this is only need for the first layer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1inVwa3UgfO"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOD-jeJrU9Ah"
      },
      "source": [
        "#  Flattening \n",
        "we need our cnn object \n",
        "We need to call the flatten class it does not take anything as parametre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ55iYzSVB8S"
      },
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9VEXtU_VrEF"
      },
      "source": [
        "# full connection  \n",
        "now we need to add a new layer which is fully connected layer which belong to keras, it take dense class, we need hidden layer so we have to choose a large number of neuran is units = 128  \n",
        "Activation function we need rectifle Relu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blBP5VyvWb_4"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItPPRU3wWmug"
      },
      "source": [
        "#Output Layer \n",
        "units=1 : we need only one neuron the output layer because we need only Dog or Cat means is binary classification \n",
        "activation='sigmoid' : because we are doing binay classification so we need to use the sigmoid  if we are doing multiclass classfication  we can use the softmax but for now as is binay we will use only the sigmoid fonction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYlhHNEmW2zo"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrW4FtrIX9mr"
      },
      "source": [
        "# Now is the part we train \n",
        "we gonna evaluate the same modele "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgtoRugTYV1k"
      },
      "source": [
        "Compiling the CNN \n",
        "optimizer = 'adam : we gonna choose adam optimizer to perform stochastic gradien descent to update the weight in order to reduce a loss error between prediction and target\n",
        "loss = 'binary_crossentropy' : we gonna choose the same loss because we doing binat classification \n",
        "metrics = ['accuracy'] : we gonna use the accuracy  because the most relevant way to mesure the performance of classification modele \n",
        "```\n",
        "# Ce texte est au format code\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np1tGfxiYGbA"
      },
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdtiIe8LZhbn"
      },
      "source": [
        "# train is evaluate \n",
        "We are not only traning the CNN but also evaluatin at the same time that why we use the validation \n",
        "evaluated on testset this how we train it \n",
        "epochs we gonna choose the 25 to get the resul pretty fast \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKwXqqThZuYY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97e79d54-b9e3-459e-f7fc-f5990fdee61f"
      },
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "207/207 [==============================] - 656s 3s/step - loss: 0.6536 - accuracy: 0.6227\n",
            "Epoch 2/25\n",
            "207/207 [==============================] - 69s 331ms/step - loss: 0.6046 - accuracy: 0.6653\n",
            "Epoch 3/25\n",
            "207/207 [==============================] - 70s 340ms/step - loss: 0.5833 - accuracy: 0.6810\n",
            "Epoch 4/25\n",
            "207/207 [==============================] - 67s 324ms/step - loss: 0.5494 - accuracy: 0.7119\n",
            "Epoch 5/25\n",
            "207/207 [==============================] - 68s 327ms/step - loss: 0.5185 - accuracy: 0.7435\n",
            "Epoch 6/25\n",
            "207/207 [==============================] - 69s 335ms/step - loss: 0.5109 - accuracy: 0.7435\n",
            "Epoch 7/25\n",
            "207/207 [==============================] - 69s 335ms/step - loss: 0.4785 - accuracy: 0.7638\n",
            "Epoch 8/25\n",
            "207/207 [==============================] - 70s 339ms/step - loss: 0.4710 - accuracy: 0.7733\n",
            "Epoch 9/25\n",
            "207/207 [==============================] - 68s 328ms/step - loss: 0.4557 - accuracy: 0.7834\n",
            "Epoch 10/25\n",
            "207/207 [==============================] - 70s 338ms/step - loss: 0.4359 - accuracy: 0.7940\n",
            "Epoch 11/25\n",
            "207/207 [==============================] - 69s 332ms/step - loss: 0.4288 - accuracy: 0.7974\n",
            "Epoch 12/25\n",
            "207/207 [==============================] - 71s 341ms/step - loss: 0.4211 - accuracy: 0.8080\n",
            "Epoch 13/25\n",
            "207/207 [==============================] - 68s 330ms/step - loss: 0.3967 - accuracy: 0.8225\n",
            "Epoch 14/25\n",
            "207/207 [==============================] - 71s 340ms/step - loss: 0.3891 - accuracy: 0.8260\n",
            "Epoch 15/25\n",
            "207/207 [==============================] - 70s 335ms/step - loss: 0.3721 - accuracy: 0.8344\n",
            "Epoch 16/25\n",
            "207/207 [==============================] - 69s 332ms/step - loss: 0.3658 - accuracy: 0.8344\n",
            "Epoch 17/25\n",
            "207/207 [==============================] - 69s 333ms/step - loss: 0.3468 - accuracy: 0.8482\n",
            "Epoch 18/25\n",
            "207/207 [==============================] - 70s 339ms/step - loss: 0.3418 - accuracy: 0.8465\n",
            "Epoch 19/25\n",
            "207/207 [==============================] - 71s 343ms/step - loss: 0.3223 - accuracy: 0.8571\n",
            "Epoch 20/25\n",
            "207/207 [==============================] - 69s 336ms/step - loss: 0.3148 - accuracy: 0.8606\n",
            "Epoch 21/25\n",
            "207/207 [==============================] - 72s 348ms/step - loss: 0.3018 - accuracy: 0.8629\n",
            "Epoch 22/25\n",
            "207/207 [==============================] - 70s 340ms/step - loss: 0.2956 - accuracy: 0.8709\n",
            "Epoch 23/25\n",
            "207/207 [==============================] - 71s 344ms/step - loss: 0.2727 - accuracy: 0.8826\n",
            "Epoch 24/25\n",
            "207/207 [==============================] - 71s 341ms/step - loss: 0.2618 - accuracy: 0.8882\n",
            "Epoch 25/25\n",
            "207/207 [==============================] - 72s 348ms/step - loss: 0.2585 - accuracy: 0.8932\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9a6e8e81c0>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MeeuCjFcEfy"
      },
      "source": [
        "# now we gonna predict our modele\n",
        "we need to import library numpy \n",
        "wen need to import that image module \n",
        "test_image  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMpCLsjUismm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "119b2d94-2e03-49d6-9ff1-064c7c7018a2"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import keras.utils as image\n",
        "\n",
        "test_image = image.load_img('/content/drive/MyDrive/dataset/single_prediction/dog7.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "    prediction = 'dog'\n",
        "else:\n",
        "    prediction = 'cat'\n",
        "print(prediction)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "dog\n"
          ]
        }
      ]
    }
  ]
}